{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b7ed144-08fa-42e0-9509-ef58630680af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 1.5.dev2442\n",
      "Numpy version: 1.26.4\n",
      "Pytorch version: 1.13.1+cu117\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False, USE_META_DICT = False\n",
      "MONAI rev id: d850fe3e5160f867a27d3f9e45f7ca1e4c7e53e5\n",
      "MONAI __file__: /opt/conda/envs/pytorch/lib/python3.10/site-packages/monai/__init__.py\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: 0.4.11\n",
      "ITK version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "Nibabel version: 5.3.2\n",
      "scikit-image version: 0.24.0\n",
      "scipy version: 1.13.1\n",
      "Pillow version: 10.4.0\n",
      "Tensorboard version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "gdown version: 5.2.0\n",
      "TorchVision version: 0.14.1+cu117\n",
      "tqdm version: 4.66.5\n",
      "lmdb version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "psutil version: 5.9.3\n",
      "pandas version: 2.2.3\n",
      "einops version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "transformers version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "mlflow version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "pynrrd version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "clearml version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "from monai.utils import first, set_determinism\n",
    "from monai.transforms import (\n",
    "    AsDiscrete,\n",
    "    AsDiscreted,\n",
    "    EnsureChannelFirstd,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    SaveImaged,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    "    Invertd,\n",
    ")\n",
    "from monai.handlers.utils import from_engine\n",
    "from monai.networks.nets import UNet\n",
    "from monai.networks.layers import Norm\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.losses import DiceLoss\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.data import CacheDataset, DataLoader, Dataset, decollate_batch\n",
    "from monai.config import print_config\n",
    "from monai.apps import download_and_extract\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import tempfile\n",
    "import shutil\n",
    "import os\n",
    "import glob\n",
    "\n",
    "print_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7247a16f-16eb-40d1-97b7-ee8baf856202",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./test_seg\n"
     ]
    }
   ],
   "source": [
    "directory = \"./test_seg\"\n",
    "if directory is not None:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "root_dir = tempfile.mkdtemp() if directory is None else directory\n",
    "print(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ad74f69-2ada-4fe7-b506-5cda82b8c23b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "resource = \"https://msd-for-monai.s3-us-west-2.amazonaws.com/Task09_Spleen.tar\"\n",
    "md5 = \"410d4a301da4e5b2f6f86ec3ddba524e\"\n",
    "\n",
    "compressed_file = os.path.join(root_dir, \"Task09_Spleen.tar\")\n",
    "data_dir = os.path.join(root_dir, \"Task09_Spleen\")\n",
    "if not os.path.exists(data_dir):\n",
    "    download_and_extract(resource, compressed_file, root_dir, md5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83a719d3-6e30-4c77-b1bb-dcd0f80e198c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_images = sorted(glob.glob(os.path.join(data_dir, \"imagesTr\", \"*.nii.gz\")))\n",
    "train_labels = sorted(glob.glob(os.path.join(data_dir, \"labelsTr\", \"*.nii.gz\")))\n",
    "data_dicts = [{\"image\": image_name, \"label\": label_name} for image_name, label_name in zip(train_images, train_labels)]\n",
    "train_files, val_files = data_dicts[:-9], data_dicts[-9:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8015964f-43c1-4d93-95c4-7e541e7e6bc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "set_determinism(seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aadda44b-f022-416c-af2b-585fb0b4f4ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pytorch/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning: monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` was changed in version 1.5 from `allow_smaller=True` to `allow_smaller=False`.\n",
      "  warn_deprecated(argname, msg, warning_category)\n"
     ]
    }
   ],
   "source": [
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "        ScaleIntensityRanged(\n",
    "            keys=[\"image\"],\n",
    "            a_min=-57,\n",
    "            a_max=164,\n",
    "            b_min=0.0,\n",
    "            b_max=1.0,\n",
    "            clip=True,\n",
    "        ),\n",
    "        CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        Spacingd(keys=[\"image\", \"label\"], pixdim=(1.5, 1.5, 2.0), mode=(\"bilinear\", \"nearest\")),\n",
    "        RandCropByPosNegLabeld(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            label_key=\"label\",\n",
    "            spatial_size=(96, 96, 96),\n",
    "            pos=1,\n",
    "            neg=1,\n",
    "            num_samples=4,\n",
    "            image_key=\"image\",\n",
    "            image_threshold=0,\n",
    "        ),\n",
    "        # user can also add other random transforms\n",
    "        # RandAffined(\n",
    "        #     keys=['image', 'label'],\n",
    "        #     mode=('bilinear', 'nearest'),\n",
    "        #     prob=1.0, spatial_size=(96, 96, 96),\n",
    "        #     rotate_range=(0, 0, np.pi/15),\n",
    "        #     scale_range=(0.1, 0.1, 0.1)),\n",
    "    ]\n",
    ")\n",
    "val_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "        ScaleIntensityRanged(\n",
    "            keys=[\"image\"],\n",
    "            a_min=-57,\n",
    "            a_max=164,\n",
    "            b_min=0.0,\n",
    "            b_max=1.0,\n",
    "            clip=True,\n",
    "        ),\n",
    "        CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        Spacingd(keys=[\"image\", \"label\"], pixdim=(1.5, 1.5, 2.0), mode=(\"bilinear\", \"nearest\")),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "738ffbc1-64f8-4c21-afd2-351130cffbd2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████| 32/32 [00:20<00:00,  1.58it/s]\n",
      "Loading dataset: 100%|██████████| 9/9 [00:04<00:00,  2.03it/s]\n"
     ]
    }
   ],
   "source": [
    "train_ds = CacheDataset(data=train_files, transform=train_transforms, cache_rate=1.0, num_workers=4)\n",
    "# train_ds = Dataset(data=train_files, transform=train_transforms)\n",
    "\n",
    "# use batch_size=2 to load images and use RandCropByPosNegLabeld\n",
    "# to generate 2 x 4 images for network training\n",
    "train_loader = DataLoader(train_ds, batch_size=2, shuffle=True, num_workers=4)\n",
    "\n",
    "val_ds = CacheDataset(data=val_files, transform=val_transforms, cache_rate=1.0, num_workers=4)\n",
    "# val_ds = Dataset(data=val_files, transform=val_transforms)\n",
    "val_loader = DataLoader(val_ds, batch_size=1, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b308bf85-1157-4e90-a029-b3f33463a8a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# standard PyTorch program style: create UNet, DiceLoss and Adam optimizer\n",
    "device = torch.device(\"cpu\")\n",
    "model = UNet(\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,\n",
    "    out_channels=2,\n",
    "    channels=(16, 32, 64, 128, 256),\n",
    "    strides=(2, 2, 2, 2),\n",
    "    num_res_units=2,\n",
    "    norm=Norm.BATCH,\n",
    ").to(device)\n",
    "loss_function = DiceLoss(to_onehot_y=True, softmax=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), 1e-4)\n",
    "dice_metric = DiceMetric(include_background=False, reduction=\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c98ac28-a7a6-4476-b769-02d712fc8d77",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "epoch 1/5\n",
      "1/16, train_loss: 0.6690\n",
      "2/16, train_loss: 0.6787\n",
      "3/16, train_loss: 0.6835\n",
      "4/16, train_loss: 0.6849\n",
      "5/16, train_loss: 0.6857\n",
      "6/16, train_loss: 0.6922\n",
      "7/16, train_loss: 0.6590\n",
      "8/16, train_loss: 0.6751\n",
      "9/16, train_loss: 0.6663\n",
      "10/16, train_loss: 0.6565\n",
      "11/16, train_loss: 0.6531\n",
      "12/16, train_loss: 0.6793\n",
      "13/16, train_loss: 0.6482\n",
      "14/16, train_loss: 0.6644\n",
      "15/16, train_loss: 0.6507\n",
      "16/16, train_loss: 0.6291\n",
      "epoch 1 average loss: 0.6672\n",
      "----------\n",
      "epoch 2/5\n",
      "1/16, train_loss: 0.6595\n",
      "2/16, train_loss: 0.6610\n",
      "3/16, train_loss: 0.6437\n",
      "4/16, train_loss: 0.6498\n",
      "5/16, train_loss: 0.6629\n",
      "6/16, train_loss: 0.6496\n",
      "7/16, train_loss: 0.6516\n",
      "8/16, train_loss: 0.6143\n",
      "9/16, train_loss: 0.6244\n",
      "10/16, train_loss: 0.6489\n",
      "11/16, train_loss: 0.6289\n",
      "12/16, train_loss: 0.6116\n",
      "13/16, train_loss: 0.6272\n",
      "14/16, train_loss: 0.6388\n",
      "15/16, train_loss: 0.6444\n",
      "16/16, train_loss: 0.6536\n",
      "epoch 2 average loss: 0.6419\n",
      "saved new best metric model\n",
      "current epoch: 2 current mean dice: 0.0314\n",
      "best mean dice: 0.0314 at epoch: 2\n",
      "----------\n",
      "epoch 3/5\n",
      "1/16, train_loss: 0.6301\n",
      "2/16, train_loss: 0.6239\n",
      "3/16, train_loss: 0.6078\n",
      "5/16, train_loss: 0.6299\n",
      "6/16, train_loss: 0.6177\n",
      "7/16, train_loss: 0.5969\n",
      "8/16, train_loss: 0.6439\n",
      "9/16, train_loss: 0.6276\n",
      "10/16, train_loss: 0.6335\n",
      "11/16, train_loss: 0.6236\n",
      "12/16, train_loss: 0.6184\n",
      "13/16, train_loss: 0.6409\n",
      "14/16, train_loss: 0.5934\n",
      "15/16, train_loss: 0.5848\n",
      "16/16, train_loss: 0.5670\n",
      "epoch 3 average loss: 0.6171\n",
      "----------\n",
      "epoch 4/5\n",
      "1/16, train_loss: 0.6546\n",
      "2/16, train_loss: 0.6012\n",
      "3/16, train_loss: 0.6184\n",
      "4/16, train_loss: 0.6316\n",
      "5/16, train_loss: 0.5618\n",
      "6/16, train_loss: 0.6002\n",
      "7/16, train_loss: 0.6090\n",
      "8/16, train_loss: 0.5972\n",
      "9/16, train_loss: 0.6318\n",
      "10/16, train_loss: 0.5590\n",
      "11/16, train_loss: 0.6324\n",
      "12/16, train_loss: 0.6080\n",
      "13/16, train_loss: 0.6237\n",
      "14/16, train_loss: 0.5814\n",
      "15/16, train_loss: 0.6302\n",
      "16/16, train_loss: 0.5958\n",
      "epoch 4 average loss: 0.6085\n",
      "saved new best metric model\n",
      "current epoch: 4 current mean dice: 0.0463\n",
      "best mean dice: 0.0463 at epoch: 4\n",
      "----------\n",
      "epoch 5/5\n",
      "1/16, train_loss: 0.5878\n",
      "2/16, train_loss: 0.6358\n",
      "3/16, train_loss: 0.6094\n",
      "4/16, train_loss: 0.6013\n",
      "5/16, train_loss: 0.5976\n",
      "6/16, train_loss: 0.5784\n",
      "7/16, train_loss: 0.5961\n",
      "8/16, train_loss: 0.6177\n",
      "9/16, train_loss: 0.5710\n",
      "10/16, train_loss: 0.6055\n",
      "11/16, train_loss: 0.6279\n",
      "12/16, train_loss: 0.6391\n",
      "13/16, train_loss: 0.6471\n",
      "14/16, train_loss: 0.6151\n",
      "15/16, train_loss: 0.6112\n",
      "16/16, train_loss: 0.5128\n",
      "epoch 5 average loss: 0.6034\n"
     ]
    }
   ],
   "source": [
    "max_epochs = 5\n",
    "val_interval = 2\n",
    "best_metric = -1\n",
    "best_metric_epoch = -1\n",
    "epoch_loss_values = []\n",
    "metric_values = []\n",
    "post_pred = Compose([AsDiscrete(argmax=True, to_onehot=2)])\n",
    "post_label = Compose([AsDiscrete(to_onehot=2)])\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    print(\"-\" * 10)\n",
    "    print(f\"epoch {epoch + 1}/{max_epochs}\")\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "    for batch_data in train_loader:\n",
    "        step += 1\n",
    "        inputs, labels = (\n",
    "            batch_data[\"image\"].to(device),\n",
    "            batch_data[\"label\"].to(device),\n",
    "        )\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        print(f\"{step}/{len(train_ds) // train_loader.batch_size}, \" f\"train_loss: {loss.item():.4f}\")\n",
    "    epoch_loss /= step\n",
    "    epoch_loss_values.append(epoch_loss)\n",
    "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    if (epoch + 1) % val_interval == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for val_data in val_loader:\n",
    "                val_inputs, val_labels = (\n",
    "                    val_data[\"image\"].to(device),\n",
    "                    val_data[\"label\"].to(device),\n",
    "                )\n",
    "                roi_size = (160, 160, 160)\n",
    "                sw_batch_size = 4\n",
    "                val_outputs = sliding_window_inference(val_inputs, roi_size, sw_batch_size, model)\n",
    "                val_outputs = [post_pred(i) for i in decollate_batch(val_outputs)]\n",
    "                val_labels = [post_label(i) for i in decollate_batch(val_labels)]\n",
    "                # compute metric for current iteration\n",
    "                dice_metric(y_pred=val_outputs, y=val_labels)\n",
    "\n",
    "            # aggregate the final mean dice result\n",
    "            metric = dice_metric.aggregate().item()\n",
    "            # reset the status for next validation round\n",
    "            dice_metric.reset()\n",
    "\n",
    "            metric_values.append(metric)\n",
    "            if metric > best_metric:\n",
    "                best_metric = metric\n",
    "                best_metric_epoch = epoch + 1\n",
    "                torch.save(model.state_dict(), os.path.join(root_dir, \"best_metric_model.pth\"))\n",
    "                print(\"saved new best metric model\")\n",
    "            print(\n",
    "                f\"current epoch: {epoch + 1} current mean dice: {metric:.4f}\"\n",
    "                f\"\\nbest mean dice: {best_metric:.4f} \"\n",
    "                f\"at epoch: {best_metric_epoch}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d894da-bb86-4e99-8324-b0d8cefa8552",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train completed, best_metric: 0.0463 at epoch: 4\n"
     ]
    }
   ],
   "source": [
    "print(f\"train completed, best_metric: {best_metric:.4f} \" f\"at epoch: {best_metric_epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d88139d-7c2f-4d1c-a93f-6e1700759734",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "260.93054151535034\n"
     ]
    }
   ],
   "source": [
    "print(time.time() - start)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-pytorch-pytorch",
   "name": "workbench-notebooks.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m125"
  },
  "kernelspec": {
   "display_name": "PyTorch 1-13 (Local)",
   "language": "python",
   "name": "conda-env-pytorch-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
