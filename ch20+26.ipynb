{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67a3f949-dcb2-412d-91c6-316fd98d6d25",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 0, Loss: 3.2827978134155273\n",
      "Epoch 2, Batch 0, Loss: 1.4558491706848145\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "# Define a simple neural network\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)  # Flatten the input\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Custom Loss Function (L1 loss + CrossEntropy)\n",
    "class CustomLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomLoss, self).__init__()\n",
    "        self.l1 = nn.L1Loss()\n",
    "        self.cross_entropy = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, predictions, targets):\n",
    "        l1_loss = self.l1(predictions, torch.ones_like(predictions))  # Example L1 loss\n",
    "        ce_loss = self.cross_entropy(predictions, targets)  # Cross entropy loss\n",
    "        return l1_loss + ce_loss  # Combined loss\n",
    "\n",
    "# Define device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "# Create the model, optimizer, and custom loss function\n",
    "model = SimpleNet().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "custom_loss_fn = CustomLoss()\n",
    "\n",
    "# Set up TensorBoard writer\n",
    "writer = SummaryWriter('runs/custom_loss_experiment')\n",
    "\n",
    "# Load the full dataset\n",
    "dataset = datasets.MNIST('.', train=True, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "# Define the size of the subset (e.g., 10% of the full dataset)\n",
    "subset_size = int(0.1 * len(dataset))  # 10% of the data\n",
    "indices = torch.randperm(len(dataset))[:subset_size]  # Randomly choose a subset of indices\n",
    "\n",
    "# Create a subset of the dataset\n",
    "subset = Subset(dataset, indices)\n",
    "\n",
    "# Create a new DataLoader for the subset\n",
    "train_loader_subset = torch.utils.data.DataLoader(subset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Train using the subset\n",
    "for epoch in range(2):  # Train for 2 epochs as an example\n",
    "    running_loss = 0.0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader_subset):\n",
    "        # Perform the training steps here\n",
    "        #print(f\"Epoch {epoch + 1}, Batch {batch_idx + 1}, Data Shape: {data.shape}\")\n",
    "        \n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        output = model(data)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = custom_loss_fn(output, target)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Log loss to TensorBoard\n",
    "        if batch_idx % 100 == 0:  # Log every 100 batches\n",
    "            print(f'Epoch {epoch+1}, Batch {batch_idx}, Loss: {loss.item()}')\n",
    "            writer.add_scalar('Training Loss', loss.item(), epoch * len(train_loader_subset) + batch_idx)\n",
    "            \n",
    "    # Log average loss per epoch to TensorBoard\n",
    "    writer.add_scalar('Epoch Average Loss', running_loss / len(train_loader_subset), epoch)\n",
    "\n",
    "# Close the TensorBoard writer\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a58be07-c177-4b51-8dee-a2460c0950aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5545554a-3ea3-413f-8e69-134df28f4504",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-d0a8fddea5b7c1f3\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-d0a8fddea5b7c1f3\");\n",
       "          const url = new URL(\"/proxy/6006/\", window.location);\n",
       "          const port = 0;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Start TensorBoard within the Jupyter notebook\n",
    "%tensorboard --logdir=runs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03117442-b498-4a77-89fb-fd0a300c5678",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.301794052124023\n"
     ]
    }
   ],
   "source": [
    "print(time.time() - start)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-pytorch-pytorch",
   "name": "workbench-notebooks.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m125"
  },
  "kernelspec": {
   "display_name": "PyTorch 1-13 (Local)",
   "language": "python",
   "name": "conda-env-pytorch-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
